I"}<h2 id="decision-tree">Decision Tree</h2>

<p><code class="language-plaintext highlighter-rouge">Decision Tree</code> 는 Root Node를 시작으로 Decision Node를 기준으로 데이터를 분류하는 기법입니다. Decision Node에서 분류가 완료되면 Leaf Node에 도달하게되고 분류가 완료가 됩니다.</p>

<p><img src="../../assets/image/decision-tree-classification-algorithm-20201022013018389.png" alt="Machine Learning Decision Tree Classification Algorithm - Javatpoint" /></p>

<h3 id="불순도--엔트로피">불순도 &amp; 엔트로피</h3>

<p><code class="language-plaintext highlighter-rouge">불순도</code>는 분류된 데이터가 얼마만큼 섞여 있는지를 의미합니다. 하기그림을 보면 점선을 기준으로 위쪽은 두개의 데이터가 많이 섞여있고 아래에는 조금 섞여 있습니다. 불순도를 따지자면 위쪽이 불순도가 높고 아래가 불순도가 낮다고 표현합니다.</p>

<p align="center"><img src="../../assets/image/image-20201022015313963.png" alt="image-20201022015313963" style="zoom:50%;" /></p>

<p><code class="language-plaintext highlighter-rouge">엔트로피</code> 란 불순도를 수치적으로 표현한 척도입니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;math xmlns="http://www.w3.org/1998/Math/MathML" display="block"&gt;
  &lt;mi&gt;E&lt;/mi&gt;
  &lt;mi&gt;n&lt;/mi&gt;
  &lt;mi&gt;t&lt;/mi&gt;
  &lt;mi&gt;r&lt;/mi&gt;
  &lt;mi&gt;o&lt;/mi&gt;
  &lt;mi&gt;p&lt;/mi&gt;
  &lt;mi&gt;y&lt;/mi&gt;
  &lt;mo&gt;=&lt;/mo&gt;
  &lt;mo&gt;&amp;#x2212;&lt;!-- − --&gt;&lt;/mo&gt;
  &lt;munderover&gt;
    &lt;mo&gt;&amp;#x2211;&lt;!-- ∑ --&gt;&lt;/mo&gt;
    &lt;mrow class="MJX-TeXAtom-ORD"&gt;
      &lt;mi&gt;i&lt;/mi&gt;
    &lt;/mrow&gt;
    &lt;mrow class="MJX-TeXAtom-ORD"&gt;
      &lt;mi&gt;n&lt;/mi&gt;
    &lt;/mrow&gt;
  &lt;/munderover&gt;
  &lt;mo stretchy="false"&gt;(&lt;/mo&gt;
  &lt;msub&gt;
    &lt;mi&gt;p&lt;/mi&gt;
    &lt;mrow class="MJX-TeXAtom-ORD"&gt;
      &lt;mi&gt;i&lt;/mi&gt;
    &lt;/mrow&gt;
  &lt;/msub&gt;
  &lt;mo stretchy="false"&gt;)&lt;/mo&gt;
  &lt;mi&gt;l&lt;/mi&gt;
  &lt;mi&gt;o&lt;/mi&gt;
  &lt;msub&gt;
    &lt;mi&gt;g&lt;/mi&gt;
    &lt;mrow class="MJX-TeXAtom-ORD"&gt;
      &lt;mn&gt;2&lt;/mn&gt;
    &lt;/mrow&gt;
  &lt;/msub&gt;
  &lt;mo stretchy="false"&gt;(&lt;/mo&gt;
  &lt;msub&gt;
    &lt;mi&gt;p&lt;/mi&gt;
    &lt;mrow class="MJX-TeXAtom-ORD"&gt;
      &lt;mi&gt;i&lt;/mi&gt;
    &lt;/mrow&gt;
  &lt;/msub&gt;
  &lt;mo stretchy="false"&gt;)&lt;/mo&gt;
&lt;/math&gt;
</code></pre></div></div>

\[Entropy = -\sum_{i}^{n} (p_{i})log_{2}(p_{i})\]

<p><img src="../../assets/image/decision-tree.png" alt="img" style="zoom:150%;" /></p>

<p>핵심코드는 하기와 같습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_data_sample</span><span class="p">,</span> <span class="n">t_data_sample</span><span class="p">)</span> 
</code></pre></div></div>

:ET