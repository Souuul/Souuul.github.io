I"	<h2 id="svm-support-vector-machine">SVM (Support vector machine)</h2>

<p><code class="language-plaintext highlighter-rouge">Support Vector machine</code>은 데이터를 선형으로 분리하여 최적의 decision boundary (결정경계)를 찾는 알고리즘입니다.</p>

<p><img src="../../assets/image/0*lyr5-f7HRu34OLvd.png" alt="0*lyr5-f7HRu34OLvd" style="zoom: 67%;" /></p>

<p>데이터를 기반으로 support Vectors를 찾아내고 그사이의 Margin이 최대화되는 Separatin Hyperplane을 찾아냅니다. 하지만 데이터의 이상치가 있는경우에는 이상치가 support vector가 되는 경우가 발생하여 overfitting이 될 수 있습니다. 즉 이상치 처리없이 모든데이터로 SVM을 사용하면 overfitting 이 발생하고 이를 Hardmargin이라고 부릅니다. 그 반대의 상황은 Softmargin이라고 부릅니다.</p>

<h3 id="cost-c">Cost (C)</h3>

<p>하지만 모든데이터를 선형으로 정확하게 구분을 할수는 없는데 이를 해결하기위해 나온개념이 Cost(C) 입니다. C는 다른 클래스에 얼마만큼의 데이터가 들어갈지를 정합니다. C가 커지면 정확하게 선형을 구분하기위해서 overfitting이 될수 있으며 C가 너무 작으면 underfitting 가능성이 있습니다.</p>

<p align="center"><img src="../../assets/image/99C3C23359E9E4AB32.png" alt="img" /></p>

<h3 id="kernel-기법">Kernel 기법</h3>

<p>주어진 data를 고차원의 공간으로 투영(projection)하는 기법입니다. 기존차원에서 선형적으로 분류할 수 없는 데이터를 고차원에서 선형으로 분류할 수 있도록 하는 방법입니다. Kernel 기법에는 주로 3가지가 존재합니다.</p>

<blockquote>
  <ul>
    <li><strong>Linear</strong></li>
    <li><strong>Poly</strong></li>
    <li><strong>rbf</strong></li>
  </ul>
</blockquote>

<p>여기서 많이 사용되며 성능이 가장 좋은 것은 rbf kernel 이며, 매개변수 gamma를 조절해야합니다.</p>

<h3 id="gamma">gamma</h3>

<p>gamma는 데이터가 영향력을 행사하는 거리다. 결론부터 말하면 gamma가 작아지면 영향력이 커지며 underfitting이 발생하고 커지면 영향력이 작아져 overfitting 이 발생할 수 있다. gamma는 가우시안 함수의 표준편차와 관련되어 있으며 클수로 작은 표준편차를 가집니다.</p>

<p>일반적으로 C와 gamma를 결정하기위해서 Grid search를</p>
:ET