I"á?<h2 id="linear-regression-model">Linear Regression Model</h2>

<p>Linear Regressionì„ í•¨ìˆ˜ë¡œ í‘œí˜„í•˜ê¸°ì „ì— ê²½ì‚¬í•˜ê°•ë²•ì— ëŒ€í•˜ì—¬ ì•Œì•„ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.</p>

<p>í•™ìŠµë°ì´í„°ë¥¼ ê´€í†µí•˜ëŠ” í•˜ë‚˜ì˜ ì§ì„ ì´ ì¡´ì¬í•œë‹¤ëŠ” Hypothesisë¥¼ ë§Œë“¤ì–´ ë‚¼ ìˆ˜ ìˆìœ¼ë©° ê·¸ ì‹ì€ <code class="language-plaintext highlighter-rouge">H(x) = Wx +b</code>ë¼ê³  í‘œí˜„í•˜ì˜€ìŠµë‹ˆë‹¤. ê·¸ë ‡ë‹¤ë©´ ìµœì ì˜ Hypothesisë¥¼ ë§Œë“¤ê¸° ìœ„í•´ì„œëŠ” loss function í˜¹ì€ cost function ì˜  ìµœì†Œê°’ì„ êµ¬í•´ì•¼í•©ë‹ˆë‹¤.í•˜ì§€ë§Œ ì´ê²ƒì„ êµ¬í•˜ê¸° ì‰½ì§€ ì•Šê¸°ë•Œë¬¸ì— ìš°ë¦¬ëŠ” ê²½ì‚¬í•˜ê°•ë²•ì„ ì´ìš©í•˜ì—¬ ìµœì†Œê°’ì— ê·¼ì‚¬í•œ ê°’ì„ êµ¬í•´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.</p>

<h4 id="ê²½ì‚¬í•˜ê°•ë²•">ê²½ì‚¬í•˜ê°•ë²•</h4>

<p>ì•„ë˜ ê·¸ë¦¼ëŒ€ë¡œ ì†ì‹¤í•¨ìˆ˜ ê·¸ë˜í”„ë¥¼ ë”°ë¼ê°€ë©´ì„œ ì†ì‹¤í•¨ìˆ˜ê°€ ìµœì†Œê°€ ë˜ëŠ” ì§€ì ì—ì„œì˜ Wë¥¼ êµ¬í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. Wê°€ ë³€í™”í•˜ë©´ì„œ HypothesisëŠ” ì˜¤ë¥¸ìª½ ì•„ë˜ì˜ ê·¸ë¦¼ì²˜ëŸ¼ ë³€í™”í•˜ê²Œ ë©ë‹ˆë‹¤.</p>

<p align="center"><img src="../../assets/image/image-20200922223143462.png" alt="image-20200922223143462" /></p>

<p>ì´ê²ƒì„ ìˆ˜ì‹ìœ¼ë¡œ í‘œí˜„í•˜ë©´ í•˜ê¸°ì™€ ê°™ìŠµë‹ˆë‹¤.</p>

<p><img src="../../assets/image/image-20200922230346991.png" alt="image-20200922230346991" style="zoom:20%;" /></p>

<p>ê²½ì‚¬í•˜ê°•ë²•ì˜ ë‹¤ìŒ ë„ì°©ì ì€ Wì™€ Î±(Learning rate) ê·¸ë¦¬ê³  ì†ì‹¤í•¨ìˆ˜ì˜ ë¯¸ë¶„ê°’ê³±ì˜ ì°¨ë¡œ ê²°ì •ë©ë‹ˆë‹¤. ì—¬ê¸°ì„œ Learning rate ê°’ì´ ë„ˆë¬´ í¬ê±°ë‚˜ ì‘ìœ¼ë©´ í•˜ê¸° ê·¸ë¦¼ê³¼ ê°™ì€ ìƒí™©ì´ ë²Œì–´ì§€ê²Œ ë©ë‹ˆë‹¤.</p>

<p align="center"><img src="../../assets/image/image-20200922230706564.png" alt="image-20200922230706564" style="zoom:50%;" /></p>

<p>ê·¸ë ‡ê¸° ë•Œë¬¸ì— ì ì ˆí•œ Î±ì„ ì°¾ì•„ì„œ ë°°ì •í•´ì£¼ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.</p>

<p>ê·¸ë ‡ë‹¤ë©´ ì´ë²ˆì—ëŠ” ì½”ë“œë¡œì„œ í‘œí˜„ì„ í•´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. í•™ìŠµë°ì´í„°ëŠ” ì´ì „ì‹œê°„ì— ì‚¬ìš©í•˜ì˜€ë˜ ê³µë¶€ì‹œê°„ê³¼ ì‹œí—˜ì ìˆ˜ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ë™ì¼í•˜ê²Œ ì‚¬ìš©í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.</p>

<ol>
  <li>
    <p>Training Data Setì„ ì¤€ë¹„
ë¨¸ì‹ ëŸ¬ë‹ì— ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©ë  ë°ì´í„°ë¥¼ NumPy array(ndarray)í˜•íƒœë¡œ ì¤€ë¹„!</p>
  </li>
  <li>
    <p>Linear Regression Modelì„ ì •ì˜
y = Wx + b =&gt; modelì„ í”„ë¡œê·¸ë¨ì ìœ¼ë¡œ í‘œí˜„
W ì™€ bì— ëŒ€í•œ ë³€ìˆ˜ ì„ ì–¸í•œ í›„ ì´ˆê¸°ê°’ì€ ëœë¤ê°’ì„ ì´ìš©í•  êº¼ì—ìš”!!</p>
  </li>
  <li>
    <p>loss functionì„ ì •ì˜ : ì†ì‹¤í•¨ìˆ˜(loss function)ì— ëŒ€í•œ ì½”ë“œë¥¼ ì‘ì„±
matrixì²˜ë¦¬í•´ì•¼í•´ìš”!!</p>
  </li>
  <li>
    <p>learning rateì˜ ì •ì˜ : ì¼ë°˜ì ìœ¼ë¡œ customizingì´ ë˜ëŠ” ê°’ìœ¼ë¡œ ì´ˆê¸°ì—ëŠ” 
0.001ì •ë„ë¡œ ì„¤ì •í•´ì„œ ì‚¬ìš©í•˜ê³  lossê°’ì„ ë³´ê³  ìˆ˜ì¹˜ë¥¼ ì¡°ì ˆí•  í•„ìš”ê°€ ìˆì–´ìš”!!</p>
  </li>
  <li>
    <p>í•™ìŠµì„ ì§„í–‰ : ë°˜ë³µì ìœ¼ë¡œ í¸ë¯¸ë¶„ì„ ì´ìš©í•´ì„œ Wì™€ bë¥¼ updateí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ êµ¬í˜„</p>
  </li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s">'ê³µë¶€ì‹œê°„(x)'</span> <span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">13</span><span class="p">,</span><span class="mi">14</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="mi">18</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">25</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">30</span><span class="p">],</span>
       <span class="s">'ì‹œí—˜ì ìˆ˜(t)'</span><span class="p">:[</span><span class="mi">5</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">31</span><span class="p">,</span><span class="mi">40</span><span class="p">,</span><span class="mi">44</span><span class="p">,</span><span class="mi">46</span><span class="p">,</span><span class="mi">49</span><span class="p">,</span><span class="mi">60</span><span class="p">,</span><span class="mi">62</span><span class="p">,</span><span class="mi">70</span><span class="p">,</span><span class="mi">80</span><span class="p">,</span><span class="mi">85</span><span class="p">,</span><span class="mi">91</span><span class="p">,</span><span class="mi">92</span><span class="p">,</span><span class="mi">97</span><span class="p">,</span><span class="mi">98</span><span class="p">]}</span>
<span class="n">x_data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">13</span><span class="p">,</span><span class="mi">14</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="mi">18</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">25</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">30</span><span class="p">]).</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">t_data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">31</span><span class="p">,</span><span class="mi">40</span><span class="p">,</span><span class="mi">44</span><span class="p">,</span><span class="mi">46</span><span class="p">,</span><span class="mi">49</span><span class="p">,</span><span class="mi">60</span><span class="p">,</span><span class="mi">62</span><span class="p">,</span><span class="mi">70</span><span class="p">,</span><span class="mi">80</span><span class="p">,</span><span class="mi">85</span><span class="p">,</span><span class="mi">91</span><span class="p">,</span><span class="mi">92</span><span class="p">,</span><span class="mi">97</span><span class="p">,</span><span class="mi">98</span><span class="p">]).</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>

<span class="c1">#ë°ì´í„°ì˜ ë¶„í¬ë¥¼ scatterë¡œ í™•ì¸
</span>
<span class="c1"># plt.scatter(x_data.ravel(), y_data.ravel()) # ravel() ë¬´ì¡°ê±´ 1ì°¨ì›ìœ¼ë¡œ ë³€ê²½
# plt.show()
</span>
<span class="c1"># Linear Regression Modelì„ ì •ì˜
# y = Wx+b
</span><span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># matrix
</span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>   <span class="c1"># scalar
</span>
<span class="c1"># H = W*x + b # yëŒ€ì‹ ì— Hypothesis ë¥¼ ë‚˜íƒ€ë‚´ëŠ” Hë¥¼ ë³€ìˆ˜ëª…ìœ¼ë¡œ ì¼ì–´ìš”!
</span>
<span class="c1"># loss function 
</span><span class="k">def</span> <span class="nf">loss_func</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">t</span><span class="p">):</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">W</span><span class="p">)</span><span class="o">+</span><span class="n">b</span> 
    
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">power</span><span class="p">((</span><span class="n">t</span><span class="o">-</span><span class="n">y</span><span class="p">),</span><span class="mi">2</span><span class="p">))</span>

<span class="c1"># ë¯¸ë¶„í•¨ìˆ˜
</span>
<span class="k">def</span> <span class="nf">numerical_derivative</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">delta_x</span> <span class="o">=</span> <span class="mf">1e-4</span>
    <span class="n">derivative_x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    
    <span class="n">it</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">nditer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">flags</span><span class="o">=</span><span class="p">[</span><span class="s">'multi_index'</span><span class="p">])</span>
    
    <span class="k">while</span> <span class="ow">not</span> <span class="n">it</span><span class="p">.</span><span class="n">finished</span><span class="p">:</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">it</span><span class="p">.</span><span class="n">multi_index</span>
        
        <span class="n">tmp</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        
        <span class="n">x</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">=</span> <span class="n">tmp</span> <span class="o">+</span> <span class="n">delta_x</span>
        <span class="n">fx_plus_delta</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="n">x</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">=</span> <span class="n">tmp</span> <span class="o">-</span> <span class="n">delta_x</span>
        <span class="n">fx_minus_delta</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="n">derivative_x</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">fx_plus_delta</span> <span class="o">-</span> <span class="n">fx_minus_delta</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">delta_x</span><span class="p">)</span>
        
        <span class="n">x</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp</span>
        
        <span class="n">it</span><span class="p">.</span><span class="n">iternext</span><span class="p">()</span>
        
        
    <span class="k">return</span> <span class="n">derivative_x</span>

<span class="c1"># prediction
</span><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">W</span><span class="p">)</span><span class="o">+</span><span class="n">b</span> <span class="c1"># Hypthesis, Linear Regression Model
</span>
<span class="c1"># learning rateë¼ëŠ” ìƒìˆ˜ê°€ í•„ìš”, ì •ì˜í•´ì•¼í•´ìš”!
</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.0001</span>

<span class="c1"># ë¯¸ë¶„ì„ ì§„í–‰í•  loss_funcì— ëŒ€í•œ lambda í•¨ìˆ˜ë¥¼ ì •ì˜
</span><span class="n">f</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">loss_func</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">t_data</span><span class="p">)</span>

<span class="c1"># í•™ìŠµì„ ì§„í–‰!!
# ë°˜ë³µí•´ì„œ í•™ìŠµì„ ì§„í–‰ ( W ì™€ bë¥¼ updateí•˜ë©´ì„œ ë°˜ë³µì ìœ¼ë¡œ í•™ìŠµì„ ì§„í–‰)
</span><span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">90000</span><span class="p">):</span>
    <span class="n">W</span> <span class="o">=</span> <span class="n">W</span> <span class="o">-</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">numerical_derivative</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="c1"># Wì˜ í¸ë¯¸ë¶„
</span>    <span class="n">b</span> <span class="o">=</span> <span class="n">b</span> <span class="o">-</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">numerical_derivative</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span> <span class="c1"># Wì˜ í¸ë¯¸ë¶„
</span>    
    <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">3000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'W : {}, b : {}, loss : {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">W</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">loss_func</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">t_data</span><span class="p">)))</span>

<span class="c1"># í•™ìŠµ ì¢…ë£Œ í›„
</span>
<span class="k">print</span><span class="p">(</span><span class="n">predict</span><span class="p">(</span><span class="mi">19</span><span class="p">))</span>

<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_data</span><span class="p">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">t_data</span><span class="p">.</span><span class="n">ravel</span><span class="p">())</span>

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_data</span><span class="p">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span><span class="n">W</span><span class="p">)</span><span class="o">+</span><span class="n">b</span><span class="p">,</span> <span class="s">'r'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

:ET