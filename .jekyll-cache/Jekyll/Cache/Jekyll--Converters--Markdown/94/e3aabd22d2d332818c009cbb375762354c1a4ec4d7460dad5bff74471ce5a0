I"^<h2 id="vgg16">VGG16</h2>

<p>이번시간에는 VGG에 대하여 알아보겠습니다. VGG는 CNN Architecures에 하나로 공간데이터를 분석하는데 이점이 있습니다.</p>

<p>VGG는 네트워크의 깊이를 깊이와 성능사이의 영향에 대하여 알기위하여 시작되었고, 깊이를 깊게하기 위하여 3X3필터를 사용하였다. 그 이유는 필터의 크기가 커지면 이미지가 쉽게 작아지기 때문에 3X3 필터를 이용했다고 보면된다. 결과적으로는 네트워크의 깊이가 깊어지면 성능이 높아진다는 것이 밝혀졌기때문에 VGG16, VGG19와 같은 깊은 네트워크 이후로 생겨났습니다.</p>

<h3 id="필터의-크기와의-상관관계">필터의 크기와의 상관관계</h3>

<p>그렇다면 필터크기가 작은 것은 정확하게 어떤 영향을 미치는지 알아보겠습니다.</p>

<h4 id="결정-함수의-비선형성-증가">결정 함수의 비선형성 증가</h4>

<p>각 Convolution 연산은 ReLU 함수를 포함한다. 다시 말해, 1-layer 7x7 필터링의 경우 한 번의 비선형 함수가 적용되는 반면 3-layer 3x3 필터링은 세 번의 비선형 함수가 적용된다.</p>

<p>따라서, 레이어가 증가함에 따라 비선형성이 증가하게 되고 이것은 모델의 특징 식별성 증가로 이어진다.</p>

<h4 id="학습-파라미터-수의-감소">학습 파라미터 수의 감소</h4>

<p>Convolutional Network 구조를 학습할 때, 학습 대상인 가중치(weight)는 필터의 크기에 해당합니다.</p>

<p>따라서, 7x7필터 1개에 대한 학습 파라미터 수는 49이며 3x3 필터 3개에 대한 학습 파라미터 수는 27(3x3x3)이 된다.</p>

<p>향후 논문에 대하여는 추가적으로 정리하여 올리도록 하겠습니다.</p>

<p><img src="../../assets/image/img.png" alt="img" /></p>

<h3 id="vgg-16-architecture">VGG-16 Architecture</h3>

<ul>
  <li>13 Convolution Layers + 3 Fully-connected Layers</li>
  <li>3x3 convolution filters</li>
  <li>stride: 1 &amp; padding: 1</li>
  <li>2x2 max pooling (stride : 2)</li>
  <li>ReLU</li>
</ul>

:ET